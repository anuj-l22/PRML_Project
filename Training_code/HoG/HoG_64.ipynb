{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ef31247-7f2b-4cf3-81a5-faf599c99509",
   "metadata": {},
   "source": [
    "# This notebook consists of loading extracted HoG features , applying PCA on it and then some models for testing and then storing in .pkl files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd1adae-e475-4abf-a6be-c62063efa8e5",
   "metadata": {},
   "source": [
    "### Loading PCA transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7b503f8-9bd0-43cc-8753-362ff87ab301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PCA model\n",
    "import joblib\n",
    "pca_loaded = joblib.load('pca_model.joblib')\n",
    "\n",
    "# Load the transformed data\n",
    "transformed_data_32 = joblib.load('HoG_transformed_data_32.joblib')\n",
    "transformed_data_64 = joblib.load('HoG_transformed_data_64.joblib')\n",
    "transformed_data_128 = joblib.load('HoG_transformed_data_128.joblib')\n",
    "\n",
    "# Now, transformed_data_32, transformed_data_64, and transformed_data_128 can be used as needed\n",
    "y = joblib.load('labels.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74679244-d6f6-4f7b-aaae-2070438f258b",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f5d57f2-56b3-4ca0-aec4-1c91b9b03663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit model : 33.641740798950195\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "accuracies_RF = {}\n",
    "import time\n",
    "# Initialize the Random Forest model\n",
    "# You can adjust n_estimators and max_features to balance between performance and training time\n",
    "rf_model = RandomForestClassifier(n_estimators=10, max_depth = 20 , max_features='sqrt', random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train the Random Forest model on the dataset\n",
    "# Use transformed_data_32, transformed_data_64, or transformed_data_128 depending on the PCA components you want to use\n",
    "start_time = time.time()\n",
    "rf_model.fit(transformed_data_64, y)\n",
    "end_time = time.time()\n",
    "elapsed_time =  end_time - start_time\n",
    "print(\"Time taken to fit model :\" ,elapsed_time)\n",
    "# Save the trained Random Forest model\n",
    "joblib.dump(rf_model, 'HoG_random_forest_model_64_features.pkl')\n",
    "# Print accuracy on the training dataset\n",
    "accuracies_RF['64'] = rf_model.score(transformed_data_64, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0afe0f0-8f84-4b0c-86f7-d103d62b5e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39242802085694856\n"
     ]
    }
   ],
   "source": [
    "print(accuracies_RF['64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56124bd-8ea5-4612-a827-a0b98abd843e",
   "metadata": {},
   "source": [
    "### XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3d3d86a-7dfb-4a90-9db6-46c75bf6bcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit model : 228.50193333625793\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "import time\n",
    "# Assuming transformed_data_32, transformed_data_64, and transformed_data_128 are your feature sets\n",
    "# and 'y' is your target variable with class labels\n",
    "\n",
    "# Encode the class labels in 'y'\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Initialize a dictionary to store accuracies for different feature sets\n",
    "accuracies_XGB = {}\n",
    "\n",
    "# Set n_jobs to -1 to use all available cores\n",
    "xgb_model_64 = xgb.XGBClassifier(n_estimators=20, max_depth=20, random_state=42, n_jobs=-1)\n",
    "start_time = time.time()\n",
    "xgb_model_64.fit(transformed_data_64, y_encoded)\n",
    "end_time = time.time()\n",
    "elapsed_time =  end_time - start_time\n",
    "print(\"Time taken to fit model :\" ,elapsed_time)\n",
    "joblib.dump(xgb_model_64, 'HoG_xgb_model_64_features.pkl')\n",
    "predictions_64 = xgb_model_64.predict(transformed_data_64)\n",
    "accuracies_XGB['64'] = accuracy_score(y_encoded, predictions_64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1553708-d227-45ab-88d8-61c163b9841e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21824227310511599\n"
     ]
    }
   ],
   "source": [
    "print(accuracies_XGB['64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e77766-38ac-4db5-abf9-fa45a913b261",
   "metadata": {},
   "source": [
    "### LogisticRegression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "134358f2-fd57-482f-bdc2-b515e779c8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit model : 1948.2772254943848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "import time\n",
    "accuracies = {}\n",
    "\n",
    "# Train logistic regression for 64 PCA components\n",
    "clf_64 = LogisticRegression(solver='saga', penalty='l2', max_iter=1000, tol=0.01, n_jobs=-1)\n",
    "start_time = time.time()\n",
    "clf_64.fit(transformed_data_64, y)\n",
    "end_time = time.time()\n",
    "elapsed_time =  end_time - start_time\n",
    "print(\"Time taken to fit model :\" ,elapsed_time)\n",
    "joblib.dump(clf_64, 'HoG_logistic_regression_64_features.pkl')\n",
    "accuracies['64'] = clf_64.score(transformed_data_64, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bed13292-9932-4852-9e8a-8204de19af6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8294415476460364\n"
     ]
    }
   ],
   "source": [
    "print(accuracies['64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cc369d-70e9-4f01-b207-5988b6fabaf8",
   "metadata": {},
   "source": [
    "### LinearSVC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ea25c87-73d2-44c5-a8a9-ba1f1ed399a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anuj\\miniconda3\\envs\\PRML\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj\\miniconda3\\envs\\PRML\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit model : 1410.3899540901184\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "accuracies_SVM = {}\n",
    "\n",
    "# Initialize the LinearSVC\n",
    "linear_svm_model = LinearSVC(C=1.0, random_state=42, max_iter=1000)\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the LinearSVC model on the dataset with 64 PCA components\n",
    "linear_svm_model.fit(transformed_data_64, y)\n",
    "\n",
    "# Calculate elapsed time\n",
    "end_time = time.time()\n",
    "elapsed_time =  end_time - start_time\n",
    "print(\"Time taken to fit model :\" ,elapsed_time)\n",
    "\n",
    "# Save the trained SVM model\n",
    "joblib.dump(linear_svm_model, 'HoG_linear_svc_64_features.pkl')\n",
    "\n",
    "# Print accuracy on the training dataset\n",
    "accuracies_SVM['64'] = linear_svm_model.score(transformed_data_64, y)\n",
    "\n",
    "# Print the time taken to train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "327e0f2c-d554-4026-811e-e7f5748d7cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8227159374291544\n"
     ]
    }
   ],
   "source": [
    "print(accuracies_SVM['64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f5299b-1de8-4cfe-8cc2-9b84a1c98a73",
   "metadata": {},
   "source": [
    "### KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32149474-bd63-4555-9e31-a63e6ab0c1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n",
    "\n",
    "accuracies_KNN = {}\n",
    "\n",
    "# Initialize the KNN model\n",
    "# You can adjust 'n_neighbors' and other parameters to balance between performance and training time\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "\n",
    "# Train the KNN model on the dataset using 32 PCA components\n",
    "# You can change to transformed_data_64 or transformed_data_128 as needed\n",
    "knn_model.fit(transformed_data_64, y)\n",
    "\n",
    "# Save the trained KNN model\n",
    "joblib.dump(knn_model, 'HoG_knn_model_64_features.pkl')\n",
    "\n",
    "# Print accuracy on the training dataset\n",
    "accuracies_KNN['64'] = knn_model.score(transformed_data_64, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0bcde23-34e4-4fea-bc1e-741ac4140f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25534648227915063\n"
     ]
    }
   ],
   "source": [
    "print(accuracies_KNN['64'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
