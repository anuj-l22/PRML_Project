{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeb20992-1769-41eb-b7e5-2bd028ac91c2",
   "metadata": {},
   "source": [
    "# This notebook consists of loading extracted HoG features , applying PCA on it and then some models for testing and then storing in .pkl files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64655121-0e4f-4bbd-9a4e-2e954d3da872",
   "metadata": {},
   "source": [
    "### Loading PCA transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39ab61bf-9aad-48cc-8352-e3cb98bec071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PCA model\n",
    "import joblib\n",
    "pca_loaded = joblib.load('pca_model.joblib')\n",
    "\n",
    "# Load the transformed data\n",
    "transformed_data_32 = joblib.load('HoG_transformed_data_32.joblib')\n",
    "transformed_data_64 = joblib.load('HoG_transformed_data_64.joblib')\n",
    "transformed_data_128 = joblib.load('HoG_transformed_data_128.joblib')\n",
    "\n",
    "# Now, transformed_data_32, transformed_data_64, and transformed_data_128 can be used as needed\n",
    "y = joblib.load('labels.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14843db-db8b-4665-8d93-00b05ae6aa89",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd77c4ab-ada7-45ac-b51d-93e7adfd5969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit model : 225.38625168800354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "accuracies_RF = {}\n",
    "import time\n",
    "# Initialize the Random Forest model\n",
    "# You can adjust n_estimators and max_features to balance between performance and training time\n",
    "rf_model = RandomForestClassifier(n_estimators=10, max_depth = 20 , max_features='sqrt', random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train the Random Forest model on the dataset\n",
    "# Use transformed_data_32, transformed_data_64, or transformed_data_128 depending on the PCA components you want to use\n",
    "start_time = time.time()\n",
    "rf_model.fit(transformed_data_128, y)\n",
    "end_time = time.time()\n",
    "elapsed_time =  end_time - start_time\n",
    "print(\"Time taken to fit model :\" ,elapsed_time)\n",
    "# Save the trained Random Forest model\n",
    "joblib.dump(rf_model, 'HoG_random_forest_model_128_features.pkl')\n",
    "# Print accuracy on the training dataset\n",
    "accuracies_RF['128'] = rf_model.score(transformed_data_128, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0d39bb3-5026-4089-af9b-cf5d06f498e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3667346784553767\n"
     ]
    }
   ],
   "source": [
    "print(accuracies_RF['128'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0654742c-d754-4146-ada6-8ebdd9c86fb5",
   "metadata": {},
   "source": [
    "### XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4d47b56-6936-4944-8bb2-edc89420ee06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit model : 554.7408919334412\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "import time\n",
    "# Assuming transformed_data_32, transformed_data_64, and transformed_data_128 are your feature sets\n",
    "# and 'y' is your target variable with class labels\n",
    "\n",
    "# Encode the class labels in 'y'\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Initialize a dictionary to store accuracies for different feature sets\n",
    "accuracies_XGB = {}\n",
    "\n",
    "# Set n_jobs to -1 to use all available cores\n",
    "xgb_model_128 = xgb.XGBClassifier(n_estimators=20, max_depth=20, random_state=42, n_jobs=-1)\n",
    "start_time = time.time()\n",
    "xgb_model_128.fit(transformed_data_128, y_encoded)\n",
    "end_time = time.time()\n",
    "elapsed_time =  end_time - start_time\n",
    "print(\"Time taken to fit model :\" ,elapsed_time)\n",
    "joblib.dump(xgb_model_128, 'HoG_xgb_model_128_features.pkl')\n",
    "predictions_128 = xgb_model_128.predict(transformed_data_128)\n",
    "accuracies_XGB['128'] = accuracy_score(y_encoded, predictions_128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a9bcf6e-0f52-4572-bb2b-acacafae2209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.230559963727046\n"
     ]
    }
   ],
   "source": [
    "print(accuracies_XGB['128'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029baebf-e0d1-4942-8a42-70262c90b5ee",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b38eab96-f627-40eb-9c43-8525fdf8f634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit model : 3149.9349443912506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "import time\n",
    "accuracies = {}\n",
    "\n",
    "# Train logistic regression for 128 PCA components\n",
    "clf_128 = LogisticRegression(solver='saga', penalty='l2', max_iter=1000, tol=0.01, n_jobs=-1)\n",
    "start_time = time.time()\n",
    "clf_128.fit(transformed_data_128, y)\n",
    "end_time = time.time()\n",
    "elapsed_time =  end_time - start_time\n",
    "print(\"Time taken to fit model :\" ,elapsed_time)\n",
    "joblib.dump(clf_128, 'HoG_logistic_regression_128_features.pkl')\n",
    "accuracies['128'] = clf_128.score(transformed_data_128, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed4103cd-189a-410f-b8c6-12a7eb706cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966976498148568\n"
     ]
    }
   ],
   "source": [
    "print(accuracies['128'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d69a592-4756-4327-947d-477547c994fc",
   "metadata": {},
   "source": [
    "### LinearSVC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73d2456a-777b-4ec6-a838-58274ffc6916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anuj\\miniconda3\\envs\\PRML\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj\\miniconda3\\envs\\PRML\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit model : 2170.88875412941\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "accuracies_SVM = {}\n",
    "\n",
    "# Initialize the LinearSVC\n",
    "linear_svm_model = LinearSVC(C=1.0, random_state=42, max_iter=1000)\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the LinearSVC model on the dataset with 128 PCA components\n",
    "linear_svm_model.fit(transformed_data_128, y)\n",
    "\n",
    "# Calculate elapsed time\n",
    "end_time = time.time()\n",
    "elapsed_time =  end_time - start_time\n",
    "print(\"Time taken to fit model :\" ,elapsed_time)\n",
    "\n",
    "# Save the trained SVM model\n",
    "joblib.dump(linear_svm_model, 'HoG_linear_svc_128_features.pkl')\n",
    "\n",
    "# Print accuracy on the training dataset\n",
    "accuracies_SVM['128'] = linear_svm_model.score(transformed_data_128, y)\n",
    "\n",
    "# Print the time taken to train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1604016-58b9-43ef-a78e-a3238cab91dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965313987757878\n"
     ]
    }
   ],
   "source": [
    "print(accuracies_SVM['128'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9893e340-db2f-419a-b7db-c2381f6f0ead",
   "metadata": {},
   "source": [
    "### KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "478798fb-d810-42f1-8350-e2ec460fef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n",
    "\n",
    "accuracies_KNN = {}\n",
    "\n",
    "# Initialize the KNN model\n",
    "# You can adjust 'n_neighbors' and other parameters to balance between performance and training time\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "\n",
    "# Train the KNN model on the dataset using 32 PCA components\n",
    "# You can change to transformed_data_64 or transformed_data_128 as needed\n",
    "knn_model.fit(transformed_data_128, y)\n",
    "\n",
    "# Save the trained KNN model\n",
    "joblib.dump(knn_model, 'HoG_knn_model_128_features.pkl')\n",
    "\n",
    "# Print accuracy on the training dataset\n",
    "accuracies_KNN['128'] = knn_model.score(transformed_data_128, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "428d7211-2ceb-4e97-bb90-e1b7929bf39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27189601753192777\n"
     ]
    }
   ],
   "source": [
    "print(accuracies_KNN['128'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
